{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_toy_dataset(n_data, noise_std, split_size, seed, state):\n",
    "    \n",
    "    rs = npr.RandomState(state)\n",
    "    inputs  = np.concatenate([np.linspace(0, 2, num=n_data//2),\n",
    "                              np.linspace(6, 8, num=n_data//2)])\n",
    "    targets = np.cos(inputs)*inputs + rs.randn(n_data) * noise_std\n",
    "    inputs  = inputs.reshape((len(inputs), 1))\n",
    "    targets = targets.reshape((len(targets), 1))\n",
    "    \n",
    "    train_count = int (split_size * n_data)\n",
    "    idx = rs.permutation(range(n_data))\n",
    "    inputs_train = inputs[idx[train_count:]]\n",
    "    inputs_test = inputs[idx[:train_count]]\n",
    "    targets_train = targets[ idx[train_count:], ]\n",
    "    targets_test = targets[ idx[:train_count], ]\n",
    "    \n",
    "    return inputs_train, inputs_test, targets_train, targets_test, 1, 1., 0.\n",
    "\n",
    "def build_boston_dataset(split_size,scale,state):\n",
    "    \n",
    "    boston = load_boston()\n",
    "    bos = pd.DataFrame(boston.data)\n",
    "    bos.columns = boston.feature_names\n",
    "    if scale == True:\n",
    "        a = bos.drop('CHAS',axis =1 )\n",
    "        a=(a-np.mean(a))/np.std(a)\n",
    "        a['CHAS']=bos['CHAS'] \n",
    "        \n",
    "    else:\n",
    "        a = bos\n",
    "        train_std = 1.\n",
    "        train_mu = 0.\n",
    "    del bos\n",
    "    \n",
    "#     rs = npr.RandomState(state)\n",
    "#     n_data = a.shape[0]\n",
    "#     train_count = int (split_size * n_data)\n",
    "#     idx = rs.permutation(range(n_data))\n",
    "#     inputs_train = a[idx[train_count:],:]\n",
    "#     inputs_test = a[idx[:train_count],:]\n",
    "#     targets_train = boston.targets[idx[train_count:]]\n",
    "#     targets_test = boston.targets[idx[:train_count]]\n",
    "    inputs, inputs_test, targets,  targets_test = cv(a, boston.target, test_size = split_size, random_state = state)\n",
    "    \n",
    "    train_std = np.std(targets)\n",
    "    train_mu = np.mean(targets)\n",
    "    targets = (targets-train_mu) / train_std\n",
    "    \n",
    "    return inputs, inputs_test, np.expand_dims(targets,1),  np.expand_dims(targets_test,1), a.shape[1], train_std, train_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yacht(split_size,state):\n",
    "    fx = open('data.txt', 'r')\n",
    "    x = []\n",
    "    y = []\n",
    "    for line in fx:\n",
    "        line = line.rsplit()\n",
    "        x.append(line[:6])\n",
    "        y.append(line[6])\n",
    "\n",
    "    x = np.array(x, dtype=float)\n",
    "    y = np.array(y, dtype=float)\n",
    "    fx.close()\n",
    "    inputs, inputs_test, targets,  targets_test = cv(x, y, test_size = split_size, random_state = state)\n",
    "    return inputs, inputs_test, np.expand_dims(targets,1),  np.expand_dims(targets_test,1), x.shape[1], train_std, test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_rmse(y_true, y_pred, y_train_std, y_train_mu):\n",
    "    y_pred = y_train_std * y_pred + y_train_mu\n",
    "    rmse = np.sqrt(np.mean((y_true-y_pred) ** 2))\n",
    "    return rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
